{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIeo0ddU2UZIMKDM5fF4SF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d73641badde64f2da6000c15fd44cd23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20caa975a148412f92ffa6448667aaa0",
              "IPY_MODEL_de9fdade2cc44a83b209f02c00fb20a5",
              "IPY_MODEL_5a0ebf6c1a9c4c8faaefb943038410c2"
            ],
            "layout": "IPY_MODEL_01b5c966a8e44c8ea7526e503a880617"
          }
        },
        "20caa975a148412f92ffa6448667aaa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e49417718d34b9698b43a00f1bc19ab",
            "placeholder": "​",
            "style": "IPY_MODEL_761b1a51cd5b4b7a9a1cae89a64c9c85",
            "value": "Downloading (…)rocessor_config.json: 100%"
          }
        },
        "de9fdade2cc44a83b209f02c00fb20a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddd2552cff83429084518b4ed8977f33",
            "max": 184990,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13a92117d8114357a0640c71252d39b5",
            "value": 184990
          }
        },
        "5a0ebf6c1a9c4c8faaefb943038410c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a56cc85d708461b8df739117ed05f93",
            "placeholder": "​",
            "style": "IPY_MODEL_6c2b3cf4b962402bbdd3f1aec6f413dc",
            "value": " 185k/185k [00:00&lt;00:00, 857kB/s]"
          }
        },
        "01b5c966a8e44c8ea7526e503a880617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e49417718d34b9698b43a00f1bc19ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "761b1a51cd5b4b7a9a1cae89a64c9c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddd2552cff83429084518b4ed8977f33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13a92117d8114357a0640c71252d39b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a56cc85d708461b8df739117ed05f93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c2b3cf4b962402bbdd3f1aec6f413dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robgon-art/faster-whisper-test/blob/main/CTranslate2_Whisper_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ctranslate2 transformers"
      ],
      "metadata": {
        "id": "YHc4krqK2KnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e5e4be-8eb1-4b09-ec25-499ced658945"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ctranslate2\n",
            "  Downloading ctranslate2-3.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.9/31.9 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from ctranslate2) (1.22.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.9/dist-packages (from ctranslate2) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, ctranslate2, huggingface-hub, transformers\n",
            "Successfully installed ctranslate2-3.13.0 huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1xbZ6MTAFukAhqEXqQEQi-ZhY1us0tFwy"
      ],
      "metadata": {
        "id": "O45oYOjs3oE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4649adc7-8bed-4cad-9d9c-3c64706bf481"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xbZ6MTAFukAhqEXqQEQi-ZhY1us0tFwy\n",
            "To: /content/CoreyTInterview-32KHz_180s.wav\n",
            "100% 11.5M/11.5M [00:00<00:00, 26.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ct2-transformers-converter --model openai/whisper-small --output_dir whisper-small-ct2\n",
        "!ct2-transformers-converter --model openai/whisper-small --output_dir whisper-small-ct2-int8 --quantization int8"
      ],
      "metadata": {
        "id": "xl76h6XE2rsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "699da20f-797d-48f4-9500-8796330f3af4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading (…)lve/main/config.json: 100% 1.97k/1.97k [00:00<00:00, 348kB/s]\n",
            "Downloading pytorch_model.bin: 100% 967M/967M [00:03<00:00, 282MB/s]\n",
            "Downloading (…)neration_config.json: 100% 3.51k/3.51k [00:00<00:00, 686kB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 842/842 [00:00<00:00, 502kB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 1.04M/1.04M [00:00<00:00, 4.95MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 2.20M/2.20M [00:01<00:00, 2.08MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 494k/494k [00:00<00:00, 83.0MB/s]\n",
            "Downloading (…)main/normalizer.json: 100% 52.7k/52.7k [00:00<00:00, 255kB/s]\n",
            "Downloading (…)in/added_tokens.json: 100% 2.08k/2.08k [00:00<00:00, 1.24MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 2.08k/2.08k [00:00<00:00, 1.26MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import binascii\n",
        "def crc32_checksum(input_string):\n",
        "    input_bytes = input_string.encode() if isinstance(input_string, str) else input_string\n",
        "    checksum = binascii.crc32(input_bytes)\n",
        "    return checksum & 0xFFFFFFFF"
      ],
      "metadata": {
        "id": "fHVU98qI9_hO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import difflib\n",
        "def different_words(str1, str2):\n",
        "    words1 = str1.split()\n",
        "    words2 = str2.split()\n",
        "    matcher = difflib.SequenceMatcher(None, words1, words2)\n",
        "    differences = []\n",
        "    for opcode, a0, a1, b0, b1 in matcher.get_opcodes():\n",
        "        if opcode == 'replace':\n",
        "            max_len = max(a1 - a0, b1 - b0)\n",
        "            for i in range(max_len):\n",
        "                a = words1[a0 + i] if a0 + i < a1 else 'NA'\n",
        "                b = words2[b0 + i] if b0 + i < b1 else 'NA'\n",
        "                differences.append((a, b))\n",
        "        elif opcode == 'delete':\n",
        "            for a in words1[a0:a1]:\n",
        "                differences.append((a, 'NA'))\n",
        "        elif opcode == 'insert':\n",
        "            for b in words2[b0:b1]:\n",
        "                differences.append(('NA', b))\n",
        "    return differences"
      ],
      "metadata": {
        "id": "zhB_y7D4_WAa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ctranslate2\n",
        "import librosa\n",
        "import transformers\n",
        "import textwrap\n",
        "import time\n",
        "\n",
        "file_name = \"/content/CoreyTInterview-32KHz_180s.wav\" # language: en\n",
        "\n",
        "# Load and resample the audio file.\n",
        "audio, _ = librosa.load(file_name, sr=16000, duration=30)\n",
        "\n",
        "# Compute the features of the first 30 seconds of audio.\n",
        "processor = transformers.WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "inputs = processor(audio, return_tensors=\"np\", sampling_rate=16000)\n",
        "features = ctranslate2.StorageView.from_array(inputs.input_features)\n",
        "\n",
        "# Describe the task in the prompt.\n",
        "# See the prompt format in https://github.com/openai/whisper.\n",
        "prompt = processor.tokenizer.convert_tokens_to_ids(\n",
        "    [\n",
        "        \"<|startoftranscript|>\",\n",
        "        \"<|en|>\",\n",
        "        \"<|transcribe|>\",\n",
        "        \"<|notimestamps|>\",  # Remove this token to generate timestamps.\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "OQ6hTuVS3VKQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d73641badde64f2da6000c15fd44cd23",
            "20caa975a148412f92ffa6448667aaa0",
            "de9fdade2cc44a83b209f02c00fb20a5",
            "5a0ebf6c1a9c4c8faaefb943038410c2",
            "01b5c966a8e44c8ea7526e503a880617",
            "5e49417718d34b9698b43a00f1bc19ab",
            "761b1a51cd5b4b7a9a1cae89a64c9c85",
            "ddd2552cff83429084518b4ed8977f33",
            "13a92117d8114357a0640c71252d39b5",
            "0a56cc85d708461b8df739117ed05f93",
            "6c2b3cf4b962402bbdd3f1aec6f413dc"
          ]
        },
        "outputId": "ffbeca90-8f78-4128-fb42-64c5af7dda2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)rocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d73641badde64f2da6000c15fd44cd23"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the int8 model on CPU.\n",
        "model = ctranslate2.models.Whisper(\"whisper-small-ct2-int8\")\n",
        "\n",
        "# Detect the language.\n",
        "results = model.detect_language(features)\n",
        "language, probability = results[0][0]\n",
        "print(\"Detected language: %s with probability: %f\" % (language, probability))\n",
        "\n",
        "# Show the encoder results\n",
        "encoder_results = model.encode(features)\n",
        "print(\"Encoder results:\", encoder_results)\n",
        "\n",
        "# Run generation for the 30-second window.\n",
        "t1 = time.time()\n",
        "results = model.generate(features, [prompt], beam_size=1, sampling_temperature=0)\n",
        "transcription_1 = processor.decode(results[0].sequences_ids[0]).strip()\n",
        "t2= time.time()\n",
        "print(\"Total Time:\", round(t2 - t1, 2), \"seconds\")\n",
        "checksum_1 = crc32_checksum(transcription_1)\n",
        "print(\"Trnascription Checksum:\", checksum_1)\n",
        "print(textwrap.fill(transcription_1, width=120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an2dOQOJ4lKD",
        "outputId": "d32ec79d-3240-487e-e4df-95379b84a103"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: <|en|> with probability: 0.997071\n",
            "Encoder results:  -0.774333 -1.40021 1.49652 ... -1.80854 -0.702311 0.326999\n",
            "[cpu:0 float32 storage viewed as 1x1500x768]\n",
            "Total Time: 9.57 seconds\n",
            "Trnascription Checksum: 2912471593\n",
            "Okay, you can still get set up. I'm just gonna do my intros. Don't laugh at me. Okay. All right. Hello and welcome to\n",
            "the Post Cafe. I'm Corey Tedrow, your host. Today we're gonna be talking about long distance tech support. And we are\n",
            "joined by Susan Rayborn Miller. She is the technology manager at the production hive in Knoxville, Tennessee. Welcome,\n",
            "Susan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Results of runs on difference instances of the same type of CPU:\n",
        "\n",
        "# Detected language: <|en|> with probability: 0.997174\n",
        "# Encoder results:  -0.795277 -1.39131 1.50737 ... -1.83052 -0.697069 0.322911\n",
        "# [cpu:0 float32 storage viewed as 1x1500x768]\n",
        "# Total Time: 8.29 seconds\n",
        "# Trnascription Checksum: 1060283712\n",
        "# Okay, you can still get set up. I'm just gonna do my intros. Don't laugh at me. Okay. All right. Hello and welcome to\n",
        "# the Post Cafe. I'm Corey Tedrow, your host. Today we're gonna be talking about long distance tech support. And we are\n",
        "# joined by Susan Rayborn Miller. She is the technology manager at the production hive in Knoxville, Tennessee. Welcome\n",
        "# Susan.\n",
        "\n",
        "# Detected language: <|en|> with probability: 0.997071                          <-- note differences\n",
        "# Encoder results:  -0.774333 -1.40021 1.49652 ... -1.80854 -0.702311 0.326999  <-- here, too\n",
        "# [cpu:0 float32 storage viewed as 1x1500x768]\n",
        "# Total Time: 9.57 seconds\n",
        "# Trnascription Checksum: 2912471593\n",
        "# Okay, you can still get set up. I'm just gonna do my intros. Don't laugh at me. Okay. All right. Hello and welcome to\n",
        "# the Post Cafe. I'm Corey Tedrow, your host. Today we're gonna be talking about long distance tech support. And we are\n",
        "# joined by Susan Rayborn Miller. She is the technology manager at the production hive in Knoxville, Tennessee. Welcome, <-- note comma\n",
        "# Susan."
      ],
      "metadata": {
        "id": "MQMlKNOsgdTw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the int8 model on GPU.\n",
        "model = ctranslate2.models.Whisper(\"whisper-small-ct2-int8\", device=\"cuda\")\n",
        "\n",
        "# Detect the language.\n",
        "results = model.detect_language(features)\n",
        "language, probability = results[0][0]\n",
        "print(\"Detected language: %s with probability: %f\" % (language, probability))\n",
        "\n",
        "# Show the encoder results\n",
        "encoder_results = model.encode(features)\n",
        "print(\"Encoder results:\", encoder_results)\n",
        "\n",
        "# Run generation for the 30-second window.\n",
        "t1 = time.time()\n",
        "results = model.generate(features, [prompt], beam_size=1, sampling_temperature=0)\n",
        "transcription_2 = processor.decode(results[0].sequences_ids[0]).strip()\n",
        "t2= time.time()\n",
        "print(\"Total Time:\", round(t2 - t1, 2), \"seconds\")\n",
        "checksum_2 = crc32_checksum(transcription_2)\n",
        "print(\"Trnascription Checksum:\", checksum_2)\n",
        "print(textwrap.fill(transcription_2, width=120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbVYDcE539Uq",
        "outputId": "886e52d3-77d8-42b1-972c-92a9cb3df2a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: <|en|> with probability: 0.997335\n",
            "Encoder results:  -0.811487 -1.45845 1.50149 ... -1.84109 -0.710835 0.246928\n",
            "[cuda:0 float32 storage viewed as 1x1500x768]\n",
            "Total Time: 0.37 seconds\n",
            "Trnascription Checksum: 1569094943\n",
            "Okay. You can still get set up. I'm just going to do my intros. Don't laugh at me. Okay. All right. Hello and welcome to\n",
            "the Post Cafe. I'm Corey Tedrow, your host. Today we're going to be talking about long distance tech support. And we are\n",
            "joined by Susan Rayborn Miller. She is the technology manager at the production hive in Knoxville, Tennessee. Welcome,\n",
            "Susan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fp32 model on CPU.\n",
        "model = ctranslate2.models.Whisper(\"whisper-small-ct2\")\n",
        "\n",
        "# Detect the language.\n",
        "results = model.detect_language(features)\n",
        "language, probability = results[0][0]\n",
        "print(\"Detected language: %s with probability: %f\" % (language, probability))\n",
        "\n",
        "# Show the encoder results\n",
        "encoder_results = model.encode(features)\n",
        "print(\"Encoder results:\", encoder_results)\n",
        "\n",
        "# Run generation for the 30-second window.\n",
        "t1 = time.time()\n",
        "results = model.generate(features, [prompt])\n",
        "transcription_3 = processor.decode(results[0].sequences_ids[0]).strip()\n",
        "t2= time.time()\n",
        "print(\"Total Time:\", round(t2 - t1, 2), \"seconds\")\n",
        "checksum_3 = crc32_checksum(transcription_3)\n",
        "print(\"Trnascription Checksum:\", checksum_3)\n",
        "print(textwrap.fill(transcription_3, width=120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxaHB--x5v-w",
        "outputId": "2ab62a70-4916-444d-a175-3817cd85b000"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: <|en|> with probability: 0.997852\n",
            "Encoder results:  -0.724928 -1.39428 1.49868 ... -1.90465 -0.740848 0.322737\n",
            "[cpu:0 float32 storage viewed as 1x1500x768]\n",
            "Total Time: 18.17 seconds\n",
            "Trnascription Checksum: 2809285841\n",
            "Okay. You can still get set up. I'm just going to do my intros. Don't laugh at me. Okay. All right. Hello and welcome to\n",
            "the post cafe. I'm Corey Tedrow, your host. Today we're going to be talking about long distance tech support. And we are\n",
            "joined by Susan Rayborn Miller. She is the technology manager at the production hive in Knoxville, Tennessee. Welcome,\n",
            "Susan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fp32 model on GPU.\n",
        "model = ctranslate2.models.Whisper(\"whisper-small-ct2\", device=\"cuda\")\n",
        "\n",
        "# Detect the language.\n",
        "results = model.detect_language(features)\n",
        "language, probability = results[0][0]\n",
        "print(\"Detected language: %s with probability: %f\" % (language, probability))\n",
        "\n",
        "# Show the encoder results\n",
        "encoder_results = model.encode(features)\n",
        "print(\"Encoder results:\", encoder_results)\n",
        "\n",
        "# Run generation for the 30-second window.\n",
        "t1 = time.time()\n",
        "results = model.generate(features, [prompt])\n",
        "transcription_4 = processor.decode(results[0].sequences_ids[0]).strip()\n",
        "t2= time.time()\n",
        "print(\"Total Time:\", round(t2 - t1, 2), \"seconds\")\n",
        "checksum_4 = crc32_checksum(transcription_4)\n",
        "print(\"Trnascription Checksum:\", checksum_4)\n",
        "print(textwrap.fill(transcription_4, width=120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gpnBCy45wsQ",
        "outputId": "ffdb2a67-aacb-431a-ece0-82fde9556a36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: <|en|> with probability: 0.997853\n",
            "Encoder results:  -0.724926 -1.39429 1.49868 ... -1.90464 -0.740849 0.322737\n",
            "[cuda:0 float32 storage viewed as 1x1500x768]\n",
            "Total Time: 0.8 seconds\n",
            "Trnascription Checksum: 2809285841\n",
            "Okay. You can still get set up. I'm just going to do my intros. Don't laugh at me. Okay. All right. Hello and welcome to\n",
            "the post cafe. I'm Corey Tedrow, your host. Today we're going to be talking about long distance tech support. And we are\n",
            "joined by Susan Rayborn Miller. She is the technology manager at the production hive in Knoxville, Tennessee. Welcome,\n",
            "Susan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"checksum_1\", checksum_1)\n",
        "print(\"checksum_2\", checksum_2)\n",
        "print(\"checksum_3\", checksum_3)\n",
        "print(\"checksum_4\", checksum_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80_EiTU_GeWn",
        "outputId": "9d6e49d9-3ec6-499f-d2c6-e24266e62392"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checksum_1 1060283712\n",
            "checksum_2 1569094943\n",
            "checksum_3 2809285841\n",
            "checksum_4 2809285841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "differences = different_words(transcription_1, transcription_2)\n",
        "if differences:\n",
        "    print(\"Different word pairs:\")\n",
        "    for word1, word2 in differences:\n",
        "        print(f\"('{word1}', '{word2}')\")\n",
        "else:\n",
        "    print(\"No different words found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36mPMUdZG_1-",
        "outputId": "dbd9a31c-e851-4645-a7b2-1df0b772d598"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Different word pairs:\n",
            "('Okay,', 'Okay.')\n",
            "('you', 'You')\n",
            "('gonna', 'going')\n",
            "('NA', 'to')\n",
            "('gonna', 'going')\n",
            "('NA', 'to')\n",
            "('Welcome', 'Welcome,')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "differences = different_words(transcription_1, transcription_3)\n",
        "if differences:\n",
        "    print(\"Different word pairs:\")\n",
        "    for word1, word2 in differences:\n",
        "        print(f\"('{word1}', '{word2}')\")\n",
        "else:\n",
        "    print(\"No different words found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpVWgk0QAH25",
        "outputId": "d1910152-d8d1-4ec1-80c3-ccf3d155215d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Different word pairs:\n",
            "('Okay,', 'Okay.')\n",
            "('you', 'You')\n",
            "('gonna', 'going')\n",
            "('NA', 'to')\n",
            "('Post', 'post')\n",
            "('Cafe.', 'cafe.')\n",
            "('gonna', 'going')\n",
            "('NA', 'to')\n",
            "('Welcome', 'Welcome,')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "differences = different_words(transcription_2, transcription_3)\n",
        "if differences:\n",
        "    print(\"Different word pairs:\")\n",
        "    for word1, word2 in differences:\n",
        "        print(f\"('{word1}', '{word2}')\")\n",
        "else:\n",
        "    print(\"No different words found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg-bVr0-LLI3",
        "outputId": "ad59ae31-4c33-4e55-c723-3dbf05e975db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Different word pairs:\n",
            "('Post', 'post')\n",
            "('Cafe.', 'cafe.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "differences = different_words(transcription_3, transcription_4)\n",
        "if differences:\n",
        "    print(\"Different word pairs:\")\n",
        "    for word1, word2 in differences:\n",
        "        print(f\"('{word1}', '{word2}')\")\n",
        "else:\n",
        "    print(\"No different words found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhtGKWFjG5Gn",
        "outputId": "07375a65-2381-42f3-cb59-4a1dc292da7d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No different words found\n"
          ]
        }
      ]
    }
  ]
}